ğŸ™ï¸ AI Voice Note Summarizer

An end-to-end AI-powered voice note summarization system that converts audio recordings into structured insights using speech recognition and a locally hosted large language model.

This project demonstrates real-world GenAI system design, including audio preprocessing, transcription, summarization, performance optimization, and robust error handling â€” all running locally and free of cost.

ğŸš€ Features

ğŸ§ Upload voice notes (mp3, wav, m4a, mp4)

ğŸ—£ï¸ Automatic speech-to-text transcription using OpenAI Whisper

ğŸ§  Structured summarization using a local LLM (Ollama)

ğŸ“Œ Generates:

Short summary

Key points

Action items (when applicable)

âš¡ Optimized to avoid re-processing using session state

ğŸ›¡ï¸ Defensive JSON parsing to prevent crashes

ğŸ†“ Fully local, no paid APIs required

ğŸ§  System Architecture
Audio / Video File
        â†“
FFmpeg (audio normalization)
        â†“
Whisper (speech â†’ text)
        â†“
Local LLM via Ollama
        â†“
Structured JSON Output
        â†“
Streamlit UI

ğŸ› ï¸ Tech Stack

Python 3.10

Streamlit â€“ UI & app framework

Whisper â€“ Speech-to-text transcription

FFmpeg â€“ Audio preprocessing

Ollama â€“ Local LLM inference

Qwen2.5 (1.5B) â€“ Fast, CPU-friendly summarization model

ğŸ“‚ Project Structure
ai-voice-note-summarizer/
â”‚
â”œâ”€â”€ app.py              # Streamlit application
â”œâ”€â”€ transcribe.py       # Whisper transcription logic
â”œâ”€â”€ summarize.py        # Local LLM summarization
â”œâ”€â”€ audio_utils.py      # Audio preprocessing (FFmpeg)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the repository
git clone https://github.com/<your-username>/ai-voice-note-summarizer.git
cd ai-voice-note-summarizer

2ï¸âƒ£ Create virtual environment
python -m venv venv
venv\Scripts\activate   # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Install FFmpeg

Download from: https://www.gyan.dev/ffmpeg/builds/

Add ffmpeg/bin to system PATH

Verify:

ffmpeg -version

5ï¸âƒ£ Install Ollama & model

Download Ollama: https://ollama.com/download

Pull the summarization model:

ollama pull qwen2.5:1.5b

â–¶ï¸ Run the App
streamlit run app.py


Then:

Upload a voice note

Wait for transcription

Click Generate Summary

View structured insights instantly

ğŸ§ª Example Output

Summary

India overtakes China as the most populated country, highlighting demographic shifts and geographic diversity.

Key Points

India now has over 1.43 billion people

Population growth trends have shifted global rankings

Geography includes the Himalayas and major plains

Action Items

(Empty when content is informational, not task-oriented)

âš¡ Performance Optimizations

Uses st.session_state to prevent re-transcription

Limits LLM context to avoid CPU hangs

Applies model-level token caps

Gracefully handles non-JSON LLM responses

ğŸ§  Key Learnings

Handling long-form audio with local AI models

Managing Streamlit re-runs and state

Optimizing GenAI pipelines for CPU-only systems

Defensive parsing for unreliable LLM outputs

Real-world tradeoffs between cost, speed, and accuracy

ğŸ† Resume Highlight

Built an end-to-end AI voice note summarization system using Whisper for speech recognition and a locally hosted LLM, with optimized performance and robust error handling.

ğŸ“Œ Future Improvements

Speaker diarization

Timestamped summaries

PDF / Markdown export

Meeting vs lecture detection

Cloud deployment option

ğŸ“„ License

This project is licensed under the MIT License.
